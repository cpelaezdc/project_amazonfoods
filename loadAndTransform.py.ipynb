{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "291bb9bb-d2da-4a44-bfb3-bd16ccfc2225",
     "showTitle": true,
     "title": "LOAD Access Key from AWS account"
    }
   },
   "outputs": [],
   "source": [
    "# pyspark functions\n",
    "from pyspark.sql.functions import *\n",
    "# URL processing\n",
    "import urllib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cb2df99-cb09-4164-9a65-725266433440",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Shared/authorisation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f281407-6d97-4fa6-a815-b935e647b721",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/mount_s3 has been unmounted.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ENCODED_SECRET_KEY = urllib.parse.quote(string=SECRET_KEY, safe=\"\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "AWS_S3_BUCKET = 'bucket-amazonfoods'\n",
    "MOUNT_NAME = '/mnt/mount_s3'\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "SOURCE_URL = 's3a://%s:%s@%s' %(ACCESS_KEY,ENCODED_SECRET_KEY,AWS_S3_BUCKET)\n",
    "try:\n",
    "    dbutils.fs.mount(SOURCE_URL, MOUNT_NAME)\n",
    "except:\n",
    "    dbutils.fs.unmount(MOUNT_NAME)\n",
    "    dbutils.fs.mount(SOURCE_URL, MOUNT_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c0745a7-a6b2-4687-9e90-bf8d382e62a6",
     "showTitle": true,
     "title": "Read data from AWS and Azure"
    }
   },
   "outputs": [],
   "source": [
    "file_location_aws = \"/mnt/mount_s3/foodsAWS.json\"\n",
    "file_location_azure = \"abfss://containeramazonfoods@saamazonfoods.dfs.core.windows.net/foodsAzure.json\"\n",
    "\n",
    "df_aws =   spark.read.json(file_location_aws, multiLine=True)\n",
    "df_azure = spark.read.json(file_location_azure, multiLine=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "455605ae-3d4a-480d-9a66-10d02a3c7785",
     "showTitle": true,
     "title": "Display schema from both DataFrame"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display Schema from AWS json file\nroot\n |-- product/productId: string (nullable = true)\n |-- review/helpfulness: string (nullable = true)\n |-- review/profileName: string (nullable = true)\n |-- review/score: string (nullable = true)\n |-- review/summary: string (nullable = true)\n |-- review/text: string (nullable = true)\n |-- review/time: string (nullable = true)\n |-- review/userId: string (nullable = true)\n\nDisplay Schema from Azure json file\nroot\n |-- product/productId: string (nullable = true)\n |-- review/helpfulness: string (nullable = true)\n |-- review/profileName: string (nullable = true)\n |-- review/score: string (nullable = true)\n |-- review/summary: string (nullable = true)\n |-- review/text: string (nullable = true)\n |-- review/time: string (nullable = true)\n |-- review/userId: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "print(\"Display Schema from AWS json file\")\n",
    "df_aws.printSchema()\n",
    "print(\"Display Schema from Azure json file\")\n",
    "df_azure.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03c73e4a-d902-4fa8-8ae6-d16205ac7496",
     "showTitle": true,
     "title": "Display total number of records from both data frames."
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records is: 568454\n"
     ]
    }
   ],
   "source": [
    "numberrecords = df_aws.count() + df_azure.count()\n",
    "print(f\"The number of records is: {numberrecords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9a35e35-1433-41f6-8fc0-f24154b83ede",
     "showTitle": true,
     "title": "Use union operation to combines both dataframes"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records is: 568454\n"
     ]
    }
   ],
   "source": [
    "df_union_dataframes = df_aws.union(df_azure)\n",
    "print(f\"The number of records is: {df_union_dataframes.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "553dcddc-4f2c-44e4-b9a7-4b4707f6242a",
     "showTitle": true,
     "title": "Rename columns from new dataframe"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display Schemna\nroot\n |-- productId: string (nullable = true)\n |-- helpfulness: string (nullable = true)\n |-- profileName: string (nullable = true)\n |-- score: string (nullable = true)\n |-- summary: string (nullable = true)\n |-- text: string (nullable = true)\n |-- time: string (nullable = true)\n |-- userId: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_union_dataframes = df_union_dataframes.withColumnRenamed(\"product/productId\",\"productId\")\n",
    "df_union_dataframes = df_union_dataframes.withColumnRenamed(\"review/helpfulness\",\"helpfulness\")\n",
    "df_union_dataframes = df_union_dataframes.withColumnRenamed(\"review/profileName\",\"profileName\")\n",
    "df_union_dataframes = df_union_dataframes.withColumnRenamed(\"review/score\",\"score\")\n",
    "df_union_dataframes = df_union_dataframes.withColumnRenamed(\"review/summary\",\"summary\")\n",
    "df_union_dataframes = df_union_dataframes.withColumnRenamed(\"review/text\",\"text\")\n",
    "df_union_dataframes = df_union_dataframes.withColumnRenamed(\"review/time\",\"time\")\n",
    "df_union_dataframes = df_union_dataframes.withColumnRenamed(\"review/userId\",\"userId\")\n",
    "\n",
    "print(\"Display Schemna\")\n",
    "df_union_dataframes.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f966e10-8658-4cae-bc02-4baf259765ef",
     "showTitle": true,
     "title": "For the analysis we don't take  the summary and text  columns.    these must be droped."
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------------+-----+----------+--------------+\n| productId|helpfulness|         profileName|score|      time|        userId|\n+----------+-----------+--------------------+-----+----------+--------------+\n|B001E4KFG0|        1/1|          delmartian|  5.0|1303862400|A3SGXH7AUHU8GW|\n|B00813GRG4|        0/0|              dll pa|  1.0|1346976000|A1D87F6ZCVE5NK|\n|B000LQOCH0|        1/1|Natalia Corres \"N...|  4.0|1219017600| ABXLMWJIXXAIN|\n|B000UA0QIQ|        3/3|                Karl|  2.0|1307923200|A395BORC6FGVXV|\n|B006K2ZZ7K|        0/0|Michael D. Bigham...|  5.0|1350777600|A1UQRSCLF8GW1T|\n+----------+-----------+--------------------+-----+----------+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['summary','text']\n",
    "df_union_dataframes = df_union_dataframes.drop(*drop_columns)\n",
    "df_union_dataframes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e08b3243-e168-4ce4-856d-4adadbb3478a",
     "showTitle": true,
     "title": "The time is in linux format, convert to stardard format"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- productId: string (nullable = true)\n |-- helpfulness: string (nullable = true)\n |-- profileName: string (nullable = true)\n |-- score: string (nullable = true)\n |-- time: integer (nullable = true)\n |-- userId: string (nullable = true)\n\n+----------+-----------+--------------------+-----+-------------------+--------------+\n| productId|helpfulness|         profileName|score|               time|        userId|\n+----------+-----------+--------------------+-----+-------------------+--------------+\n|B001E4KFG0|        1/1|          delmartian|  5.0|2011-04-27 00:00:00|A3SGXH7AUHU8GW|\n|B00813GRG4|        0/0|              dll pa|  1.0|2012-09-07 00:00:00|A1D87F6ZCVE5NK|\n|B000LQOCH0|        1/1|Natalia Corres \"N...|  4.0|2008-08-18 00:00:00| ABXLMWJIXXAIN|\n|B000UA0QIQ|        3/3|                Karl|  2.0|2011-06-13 00:00:00|A395BORC6FGVXV|\n|B006K2ZZ7K|        0/0|Michael D. Bigham...|  5.0|2012-10-21 00:00:00|A1UQRSCLF8GW1T|\n+----------+-----------+--------------------+-----+-------------------+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_unixtime,col\n",
    "\n",
    "#Convert from String to integer\n",
    "df_union_dataframes = df_union_dataframes.withColumn('time', col('time').cast('integer'))\n",
    "df_union_dataframes.printSchema()\n",
    "\n",
    "# Convert from unix_timestamp to datetime\n",
    "df_union_dataframes = df_union_dataframes.withColumn('time', from_unixtime(col('time').cast('bigint')).cast('timestamp'))\n",
    "df_union_dataframes.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd5afc1a-f503-4c69-b97c-0132c750f4c9",
     "showTitle": true,
     "title": "Convert Score column from string do double"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- productId: string (nullable = true)\n |-- helpfulness: string (nullable = true)\n |-- profileName: string (nullable = true)\n |-- score: double (nullable = true)\n |-- time: timestamp (nullable = true)\n |-- userId: string (nullable = true)\n\n+----------+-----------+--------------------+-----+-------------------+--------------+\n| productId|helpfulness|         profileName|score|               time|        userId|\n+----------+-----------+--------------------+-----+-------------------+--------------+\n|B001E4KFG0|        1/1|          delmartian|  5.0|2011-04-27 00:00:00|A3SGXH7AUHU8GW|\n|B00813GRG4|        0/0|              dll pa|  1.0|2012-09-07 00:00:00|A1D87F6ZCVE5NK|\n|B000LQOCH0|        1/1|Natalia Corres \"N...|  4.0|2008-08-18 00:00:00| ABXLMWJIXXAIN|\n|B000UA0QIQ|        3/3|                Karl|  2.0|2011-06-13 00:00:00|A395BORC6FGVXV|\n|B006K2ZZ7K|        0/0|Michael D. Bigham...|  5.0|2012-10-21 00:00:00|A1UQRSCLF8GW1T|\n+----------+-----------+--------------------+-----+-------------------+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_union_dataframes = df_union_dataframes.withColumn('score', col('score').cast('double'))\n",
    "df_union_dataframes.printSchema()\n",
    "df_union_dataframes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "027aa182-5497-4ce0-8967-5088a60d7b74",
     "showTitle": true,
     "title": "Display max and min date included in this dataframe."
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum date: 1999-10-08 00:00:00\nMaximum date: 2012-10-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max, min, col\n",
    "\n",
    "# Assuming your DataFrame is called 'df' and the time column is named 'time'\n",
    "max_date = df_union_dataframes.agg(max(col('time')).alias('max_date')).collect()[0]['max_date']\n",
    "min_date = df_union_dataframes.agg(min(col('time')).alias('min_date')).collect()[0]['min_date']\n",
    "\n",
    "print(\"Minimum date:\", min_date)\n",
    "print(\"Maximum date:\", max_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b44a8102-b484-47b0-80e4-eded92b0f066",
     "showTitle": true,
     "title": "What is the product with more reviews"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n| productId|reviews|\n+----------+-------+\n|B007JFMH8M|    913|\n+----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "df_union_dataframes.createOrReplaceTempView(\"amazon_food\")\n",
    "\n",
    "query = \"SELECT productId, count(*) as reviews FROM amazon_food GROUP BY productId ORDER BY reviews DESC LIMIT 1\"\n",
    "result_query = spark.sql(query)\n",
    "\n",
    "result_query.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "680d244d-9c45-4dc5-8ce6-67cf584c8029",
     "showTitle": true,
     "title": "Number of products in dataset"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n|number_items|\n+------------+\n|       74258|\n+------------+\n\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT count(DISTINCT(productId)) as  number_items FROM amazon_food\"\n",
    "result_query = spark.sql(query)\n",
    "\n",
    "result_query.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "764b5062-a5a7-4dd0-8844-2410de04c6dd",
     "showTitle": true,
     "title": "The top 5 of users with more reviews."
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n|        userId|number_reviews|\n+--------------+--------------+\n|A3OXHLG6DIBRW8|           448|\n|A1YUL9PCJR3JTY|           421|\n| AY12DBB0U420B|           389|\n|A281NPSIMI1C2R|           365|\n|A1Z54EM24Y40LL|           256|\n+--------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT userId,count(*)  as number_reviews FROM amazon_food group by userId ORDER BY number_reviews DESC LIMIT 5\"\n",
    "result_query = spark.sql(query)\n",
    "\n",
    "result_query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3696decd-78f4-4d48-8e33-e44520f06c73",
     "showTitle": true,
     "title": "Display the number of reviews by month from dataset"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>month</th><th>month_name</th><th>record_count</th></tr></thead><tbody><tr><td>12</td><td>December</td><td>41753</td></tr><tr><td>11</td><td>November</td><td>36986</td></tr><tr><td>10</td><td>October</td><td>55762</td></tr><tr><td>9</td><td>September</td><td>55740</td></tr><tr><td>8</td><td>August</td><td>50526</td></tr><tr><td>7</td><td>July</td><td>48419</td></tr><tr><td>6</td><td>June</td><td>44479</td></tr><tr><td>5</td><td>May</td><td>46226</td></tr><tr><td>4</td><td>April</td><td>44473</td></tr><tr><td>3</td><td>Mars</td><td>48367</td></tr><tr><td>2</td><td>February</td><td>45356</td></tr><tr><td>1</td><td>January</td><td>50367</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         12,
         "December",
         41753
        ],
        [
         11,
         "November",
         36986
        ],
        [
         10,
         "October",
         55762
        ],
        [
         9,
         "September",
         55740
        ],
        [
         8,
         "August",
         50526
        ],
        [
         7,
         "July",
         48419
        ],
        [
         6,
         "June",
         44479
        ],
        [
         5,
         "May",
         46226
        ],
        [
         4,
         "April",
         44473
        ],
        [
         3,
         "Mars",
         48367
        ],
        [
         2,
         "February",
         45356
        ],
        [
         1,
         "January",
         50367
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 21
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "month",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "month_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "record_count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%sql WITH q AS (SELECT\n    EXTRACT(MONTH FROM time) AS month,\n    CASE\n        WHEN EXTRACT(MONTH FROM time) = 1 THEN 'January'\n        WHEN EXTRACT(MONTH FROM time) = 2 THEN 'February'\n        WHEN EXTRACT(MONTH FROM time) = 3 THEN 'Mars'\n        WHEN EXTRACT(MONTH FROM time) = 4 THEN 'April'\n        WHEN EXTRACT(MONTH FROM time) = 5 THEN 'May'\n        WHEN EXTRACT(MONTH FROM time) = 6 THEN 'June'\n        WHEN EXTRACT(MONTH FROM time) = 7 THEN 'July'\n        WHEN EXTRACT(MONTH FROM time) = 8 THEN 'August'\n        WHEN EXTRACT(MONTH FROM time) = 9 THEN 'September'\n        WHEN EXTRACT(MONTH FROM time) = 10 THEN 'October'\n        WHEN EXTRACT(MONTH FROM time) = 11 THEN 'November'\n        WHEN EXTRACT(MONTH FROM time) = 12 THEN 'December'\n        \n        ELSE 'Unknown' \n    END AS month_name,\n    COUNT(*) AS record_count\nFROM\n    amazon_food\nGROUP BY\n    month,\n    month_name\nORDER BY\n    month DESC) SELECT `month`,`record_count`,`month_name` FROM q",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "month_name",
             "id": "column_eac4de676"
            },
            "x": {
             "column": "month",
             "id": "column_eac4de6711"
            },
            "y": [
             {
              "column": "record_count",
              "id": "column_eac4de6710"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "scatter",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_eac4de675": {
             "name": "record_count",
             "type": "scatter",
             "yAxis": 0
            },
            "month": {
             "type": "scatter",
             "yAxis": 0
            },
            "record_count": {
             "type": "scatter",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "045d7509-a7d0-43e5-835f-a3c0d6873737",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 13.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "selects": [
          {
           "column": "month",
           "type": "column"
          },
          {
           "column": "record_count",
           "type": "column"
          },
          {
           "column": "month_name",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": [],
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    EXTRACT(MONTH FROM time) AS month,\n",
    "    CASE\n",
    "        WHEN EXTRACT(MONTH FROM time) = 1 THEN 'January'\n",
    "        WHEN EXTRACT(MONTH FROM time) = 2 THEN 'February'\n",
    "        WHEN EXTRACT(MONTH FROM time) = 3 THEN 'Mars'\n",
    "        WHEN EXTRACT(MONTH FROM time) = 4 THEN 'April'\n",
    "        WHEN EXTRACT(MONTH FROM time) = 5 THEN 'May'\n",
    "        WHEN EXTRACT(MONTH FROM time) = 6 THEN 'June'\n",
    "        WHEN EXTRACT(MONTH FROM time) = 7 THEN 'July'\n",
    "        WHEN EXTRACT(MONTH FROM time) = 8 THEN 'August'\n",
    "        WHEN EXTRACT(MONTH FROM time) = 9 THEN 'September'\n",
    "        WHEN EXTRACT(MONTH FROM time) = 10 THEN 'October'\n",
    "        WHEN EXTRACT(MONTH FROM time) = 11 THEN 'November'\n",
    "        WHEN EXTRACT(MONTH FROM time) = 12 THEN 'December'\n",
    "        -- Add similar WHEN clauses for other months\n",
    "        ELSE 'Unknown' -- Handle unexpected values\n",
    "    END AS month_name,\n",
    "    COUNT(*) AS record_count\n",
    "FROM\n",
    "    amazon_food\n",
    "GROUP BY\n",
    "    month,\n",
    "    month_name\n",
    "ORDER BY\n",
    "    month DESC;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 422372709080280,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "loadAndTransform.py",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
